---
phase: 49-time-picker-advanced
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/time-picker/src/time-voice-input.ts
autonomous: true

must_haves:
  truths:
    - "Voice input button only renders when Web Speech API is available (feature detection)"
    - "Clicking microphone button starts speech recognition and shows listening indicator"
    - "Spoken time patterns like '3 PM', '3:30 PM', '15:30' are parsed to TimeValue"
    - "Date references like 'tomorrow' are ignored (time-only parsing)"
    - "Button is hidden on Firefox and SSR (no SpeechRecognition support)"
  artifacts:
    - path: "packages/time-picker/src/time-voice-input.ts"
      provides: "Voice input handler component wrapping Web Speech API"
      contains: "TimeVoiceInput"
  key_links:
    - from: "packages/time-picker/src/time-voice-input.ts"
      to: "Web Speech API"
      via: "SpeechRecognition / webkitSpeechRecognition constructor"
      pattern: "SpeechRecognition"
---

<objective>
Create a voice input component that wraps the Web Speech API for hands-free time input.

Purpose: Fulfills TP-20 (voice input via Web Speech API). Internal component composed by TimePicker (wired in Plan 06).
Output: New time-voice-input.ts component with microphone button, speech recognition, and time parsing.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/49-time-picker-advanced/49-RESEARCH.md
@packages/time-picker/src/time-utils.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TimeVoiceInput component with Speech API integration</name>
  <files>packages/time-picker/src/time-voice-input.ts</files>
  <action>
Create `lui-time-voice-input` internal component. Progressive enhancement: hidden when API unavailable.

1. Import from Lit (html, css, svg, nothing, isServer) and @lit-ui/core. Import `TimeValue` from `./time-utils.js`.

2. Define `TimeVoiceInput` extending `TailwindElement`:

   **Properties:**
   - `@property() locale = 'en-US';` -- recognition language
   - `@property({ type: Boolean, reflect: true }) disabled = false;`

   **Internal state:**
   - `@state() private _listening = false;`
   - `@state() private _error = '';`
   - Private `_recognition: any = null;` (SpeechRecognition instance)

   **Private getter `_speechAvailable(): boolean`:**
   ```typescript
   get _speechAvailable(): boolean {
     if (isServer) return false;
     return 'SpeechRecognition' in window || 'webkitSpeechRecognition' in window;
   }
   ```
   Never import SpeechRecognition at module level -- always access via window at runtime.

   **Private method `_startListening()`:**
   ```typescript
   private _startListening(): void {
     if (isServer || !this._speechAvailable || this._listening || this.disabled) return;

     const SR = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
     const recognition = new SR();
     recognition.continuous = false;
     recognition.interimResults = false;
     recognition.lang = this.locale;
     recognition.maxAlternatives = 1;

     recognition.onresult = (event: any) => {
       const transcript = event.results[0][0].transcript;
       const parsed = this._parseVoiceTranscript(transcript);
       if (parsed) {
         this._error = '';
         dispatchCustomEvent(this, 'ui-voice-time-select', { value: parsed, transcript });
       } else {
         this._error = 'Could not understand time';
       }
       this._listening = false;
       this._recognition = null;
     };

     recognition.onerror = (event: any) => {
       this._error = event.error === 'no-speech' ? 'No speech detected' : 'Recognition error';
       this._listening = false;
       this._recognition = null;
     };

     recognition.onend = () => {
       this._listening = false;
       this._recognition = null;
     };

     this._recognition = recognition;
     this._listening = true;
     this._error = '';
     recognition.start();
   }
   ```

   **Private method `_stopListening()`:**
   - If `_recognition`, call `_recognition.abort()`.
   - Set `_listening = false`, `_recognition = null`.

   **Private method `_parseVoiceTranscript(text: string): TimeValue | null`:**
   Parse spoken time to TimeValue, ignoring date references.
   ```typescript
   private _parseVoiceTranscript(text: string): TimeValue | null {
     const normalized = text.toLowerCase().trim();

     // Pattern 1: "3:30 PM", "3 30 PM", "15:30", "3:30"
     const colonPattern = /(\d{1,2})[:\s](\d{2})\s*(am|pm|a\.m\.|p\.m\.)?/i;
     const colonMatch = normalized.match(colonPattern);
     if (colonMatch) {
       return this._buildTimeValue(
         parseInt(colonMatch[1], 10),
         parseInt(colonMatch[2], 10),
         colonMatch[3],
       );
     }

     // Pattern 2: "3 PM", "3 AM", "15"
     const hourOnlyPattern = /(\d{1,2})\s*(am|pm|a\.m\.|p\.m\.)?(?:\s|$)/i;
     const hourMatch = normalized.match(hourOnlyPattern);
     if (hourMatch) {
       return this._buildTimeValue(
         parseInt(hourMatch[1], 10),
         0,
         hourMatch[2],
       );
     }

     // Pattern 3: Word numbers "three thirty PM" -- basic support
     const wordMap: Record<string, number> = {
       one: 1, two: 2, three: 3, four: 4, five: 5, six: 6,
       seven: 7, eight: 8, nine: 9, ten: 10, eleven: 11, twelve: 12,
       thirteen: 13, fourteen: 14, fifteen: 15, twenty: 20, thirty: 30,
       forty: 40, forty-five: 45, fifty: 50,
     };
     // Match "three thirty PM" or "three PM"
     const words = normalized.split(/\s+/);
     const hourWord = words.find(w => wordMap[w] !== undefined && wordMap[w] <= 12);
     if (hourWord) {
       const hour = wordMap[hourWord];
       const minuteWord = words.find(w => wordMap[w] !== undefined && wordMap[w] >= 15);
       const minute = minuteWord ? wordMap[minuteWord] : 0;
       const period = words.find(w => /^(am|pm)$/i.test(w));
       return this._buildTimeValue(hour, minute, period);
     }

     return null;
   }

   private _buildTimeValue(
     hour: number,
     minute: number,
     period: string | undefined,
   ): TimeValue | null {
     if (minute < 0 || minute > 59) return null;

     if (period) {
       const p = period.replace(/\./g, '').toUpperCase();
       if (p === 'PM' && hour < 12) hour += 12;
       if (p === 'AM' && hour === 12) hour = 0;
     }

     if (hour < 0 || hour > 23) return null;
     return { hour, minute, second: 0 };
   }
   ```

   **Disconnected callback:** Call `_stopListening()` to clean up.

   **SVG microphone icon:**
   ```typescript
   private _micIcon = svg`
     <path d="M12 1a4 4 0 0 0-4 4v7a4 4 0 0 0 8 0V5a4 4 0 0 0-4-4z"
           stroke="currentColor" stroke-width="2" fill="none"/>
     <path d="M19 10v2a7 7 0 0 1-14 0v-2"
           stroke="currentColor" stroke-width="2" fill="none"
           stroke-linecap="round"/>
     <line x1="12" y1="19" x2="12" y2="23"
           stroke="currentColor" stroke-width="2"
           stroke-linecap="round"/>
     <line x1="8" y1="23" x2="16" y2="23"
           stroke="currentColor" stroke-width="2"
           stroke-linecap="round"/>
   `;
   ```

   **Render:**
   - If `!_speechAvailable`, render `nothing` (hidden entirely).
   - Otherwise render:
   ```html
   <div class="voice-input-wrapper">
     <button
       type="button"
       class="voice-btn ${this._listening ? 'listening' : ''}"
       aria-label=${this._listening ? 'Listening... tap to cancel' : 'Voice input'}
       ?disabled=${this.disabled}
       @click=${this._listening ? this._stopListening : this._startListening}
     >
       <svg viewBox="0 0 24 24" class="voice-icon" aria-hidden="true">
         ${this._micIcon}
       </svg>
       ${this._listening ? html`<span class="listening-pulse"></span>` : nothing}
     </button>
     ${this._error ? html`<span class="voice-error" role="alert">${this._error}</span>` : nothing}
   </div>
   ```

   **CSS styles:**
   ```css
   :host { display: inline-block; }

   .voice-input-wrapper {
     display: inline-flex;
     align-items: center;
     gap: 0.375rem;
   }

   .voice-btn {
     position: relative;
     display: flex;
     align-items: center;
     justify-content: center;
     width: 2rem;
     height: 2rem;
     border: 1px solid var(--ui-time-picker-border, #d1d5db);
     border-radius: 50%;
     background: var(--ui-time-picker-bg, white);
     color: var(--ui-time-picker-text, #374151);
     cursor: pointer;
     transition: border-color 150ms, color 150ms;
   }

   .voice-btn:hover:not(:disabled) {
     border-color: var(--ui-time-picker-primary, #3b82f6);
     color: var(--ui-time-picker-primary, #3b82f6);
   }

   .voice-btn:focus-visible {
     outline: 2px solid var(--ui-time-picker-focus-ring, #3b82f6);
     outline-offset: 2px;
   }

   .voice-btn:disabled {
     opacity: 0.5;
     cursor: not-allowed;
   }

   .voice-btn.listening {
     border-color: var(--ui-time-picker-error, #ef4444);
     color: var(--ui-time-picker-error, #ef4444);
   }

   .voice-icon {
     width: 1rem;
     height: 1rem;
   }

   .listening-pulse {
     position: absolute;
     inset: -3px;
     border: 2px solid var(--ui-time-picker-error, #ef4444);
     border-radius: 50%;
     animation: pulse 1.5s ease-in-out infinite;
   }

   @keyframes pulse {
     0%, 100% { opacity: 0; transform: scale(1); }
     50% { opacity: 0.5; transform: scale(1.15); }
   }

   .voice-error {
     font-size: 0.75rem;
     color: var(--ui-time-picker-error, #ef4444);
   }
   ```

   Dark mode:
   ```css
   :host-context(.dark) .voice-btn {
     border-color: var(--ui-time-picker-border, #4b5563);
     background: var(--ui-time-picker-bg, #1f2937);
     color: var(--ui-time-picker-text, #d1d5db);
   }
   :host-context(.dark) .voice-btn:hover:not(:disabled) {
     border-color: var(--ui-time-picker-primary, #3b82f6);
     color: var(--ui-time-picker-primary, #3b82f6);
   }
   ```

3. Safe custom element registration at bottom.

**Key decisions:**
- Progressive enhancement: component renders nothing when Speech API unavailable.
- Never import SpeechRecognition at module level (isServer guard).
- Parse time only from voice input; ignore date words ("tomorrow", "next Monday").
- Use `any` type for SpeechRecognition to avoid TS declaration issues (it's a runtime-only API).
  </action>
  <verify>
Build: `cd packages/time-picker && npx tsc --noEmit`. No type errors.
Verify feature detection gate, speech recognition lifecycle, and voice transcript parser.
  </verify>
  <done>TimeVoiceInput component renders a microphone button (hidden when unavailable), starts speech recognition on click, parses spoken time patterns to TimeValue, and dispatches selection event.</done>
</task>

</tasks>

<verification>
1. `cd packages/time-picker && npx tsc --noEmit` passes
2. `grep -n 'SpeechRecognition\|_speechAvailable\|_parseVoiceTranscript' packages/time-picker/src/time-voice-input.ts` confirms Speech API integration
3. `grep -n 'isServer\|nothing' packages/time-picker/src/time-voice-input.ts` confirms SSR safety and progressive enhancement
</verification>

<success_criteria>
- Microphone button only renders when SpeechRecognition is available
- Button hidden on SSR and in browsers without Speech API
- Speech recognition starts/stops on button click
- Transcript parser handles "3 PM", "3:30 PM", "15:30", and basic word numbers
- Date references ignored (time-only parsing)
- Visual listening indicator with pulsing animation
- Error messages displayed via role="alert"
</success_criteria>

<output>
After completion, create `.planning/phases/49-time-picker-advanced/49-05-SUMMARY.md`
</output>
